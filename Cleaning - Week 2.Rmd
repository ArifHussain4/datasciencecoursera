---
title: "Cleaning - Week 2"
output: html_document
date: '2022-05-06'
---

## Reading from MySQL
-library(RMySQL)


## Reading my WEb --> WEbscraping
- Extracting data from HTML code of websites
- Check wiki --> web_scraping
- can use readlines()

You can also embed plots, for example:

```{r web scrape} 
data <- url("https://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en") #opens 
html_code <- readLines(data)
close(data) #closes connection
```
Can use the XML package to parse data from HTML code
```{r}
library(XML)
url <- "https://scholar.google.com/citations?user=HI-I6C0AAAAJ&amp;hl=en"
html <- htmlTreeParse(url)

#xpathSApply(html, "//title", xmlValue)

#xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
```
## Reading from get command (httr package)
- library(httr)

``` {r}
library(httr)
html2 <- GET("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&amp;hl=en") #open connection
content2 <- content(html2, as="text") #get content
parsedHTML <- htmlParse(content2, asText = TRUE) #parse to HTML
xpathSApply(parsedHTML, "//title", xmlValue) #run loop
```
##Accessing pages with passwords
- won't work with just GET() from httr package
- can authenticate using httr package: assign the handle and authenticate() command


## Getting Data from API 
- Can get these with GET requests (httr package)
- GET; POST, PUT, DELETE --> functions
- Works well with FB, Twitter, GOogle, etc.

## Other Sources
- can use:
    - file()
    - url()
    - gzfile() #zip file
    - bzfile () #zip file
- run ?connection for more info

- foreign package very useful --> read.foo. Can load from:
    - minitab, S, SAS, SPSS, MATLAB
    - read.spss
    - read.dta
    - read.mtp
    - read.octave
    - read.spss
    - read.SAS




